<div align="center">

# ğŸ–¥ï¸ AgenticOS

**Turn Windows into an AI-Navigable Desktop via CLI Chat**

[![CI](https://github.com/jiaqizou/AgenticOS-ClaudeOpus4.6/actions/workflows/ci.yml/badge.svg)](https://github.com/jiaqizou/AgenticOS-ClaudeOpus4.6/actions/workflows/ci.yml)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![Code style: ruff](https://img.shields.io/badge/code%20style-ruff-000000.svg)](https://github.com/astral-sh/ruff)

*A modular Python framework for deep OS integration and intelligent desktop automation using multi-modal LLMs.*

</div>

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     CLI / Chat Interface                     â”‚
â”‚                    (Rich + Click terminal)                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                      Agent Layer                             â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚    â”‚  Navigator    â”‚  â”‚   Planner    â”‚  â”‚   ReAct Loop â”‚     â”‚
â”‚    â”‚  (LLM core)  â”‚  â”‚  (decompose) â”‚  â”‚   (observeâ†’  â”‚     â”‚
â”‚    â”‚              â”‚  â”‚              â”‚  â”‚    thinkâ†’act) â”‚     â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                   Grounding Layer                            â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚    â”‚   UIA    â”‚    â”‚  Vision  â”‚    â”‚   OCR    â”‚             â”‚
â”‚    â”‚(pywinautoâ”‚    â”‚  (VLM)   â”‚    â”‚(RapidOCR)â”‚             â”‚
â”‚    â”‚ a11y treeâ”‚    â”‚          â”‚    â”‚          â”‚             â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    Action Layer                              â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚    â”‚Keyboardâ”‚  â”‚ Mouse  â”‚  â”‚ Shell  â”‚  â”‚ Window   â”‚        â”‚
â”‚    â”‚        â”‚  â”‚        â”‚  â”‚        â”‚  â”‚ Manager  â”‚        â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                  Observation Layer                            â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚    â”‚  Screenshot   â”‚    â”‚  GIF Recorder    â”‚                â”‚
â”‚    â”‚  (mss)        â”‚    â”‚  (imageio)       â”‚                â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚               MCP Server (FastMCP)                           â”‚
â”‚    11 tools exposed for external LLM integration             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## âœ¨ Features

- **ğŸ¤– Multi-LLM Support** â€” Claude, GPT-4o, Gemini, Ollama local models via `litellm`
- **ğŸ” Hybrid Screen Understanding** â€” UIA accessibility tree + VLM vision + OCR (three-layer fallback)
- **âŒ¨ï¸ Full Input Simulation** â€” Keyboard, mouse, shell commands, window management
- **ğŸ¬ GIF Session Recording** â€” Automatic recording of agent actions with annotations
- **ğŸ”Œ MCP Server** â€” 11 tools exposed via Model Context Protocol for external integration
- **ğŸ“Š Built-in Benchmarks** â€” 30 tasks across basic/intermediate/advanced categories
- **ğŸ›¡ï¸ Safety First** â€” Dangerous command blocklist, action confirmation, step limits

## ğŸš€ Quick Start

### Installation

```bash
# Clone the repository
git clone https://github.com/jiaqizou/AgenticOS-ClaudeOpus4.6.git
cd AgenticOS-ClaudeOpus4.6

# Install in development mode
pip install -e ".[dev]"

# Set your API key
set ANTHROPIC_API_KEY=your-key-here
```

### Usage

```bash
# Interactive chat mode
agenticos

# Single task mode
agenticos --task "Open Notepad and type Hello World"

# With a specific model
agenticos --model gpt-4o --task "Take a screenshot and save it"

# Skip action confirmations
agenticos --no-confirm --task "Open Calculator"

# Without GIF recording
agenticos --no-record --task "List files on desktop"
```

### MCP Server

```bash
# Run the MCP server (for integration with Claude Desktop, etc.)
python -m agenticos.mcp.server
```

## ğŸ“¦ Project Structure

```
AgenticOS/
â”œâ”€â”€ src/agenticos/
â”‚   â”œâ”€â”€ __init__.py              # Package root (version)
â”‚   â”œâ”€â”€ cli.py                   # Rich CLI chat interface
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ config.py            # Pydantic-settings configuration
â”‚   â”‚   â””â”€â”€ exceptions.py        # Custom exception hierarchy
â”‚   â”œâ”€â”€ observation/
â”‚   â”‚   â”œâ”€â”€ screenshot.py        # mss-based screen capture
â”‚   â”‚   â””â”€â”€ recorder.py          # Threaded GIF recorder
â”‚   â”œâ”€â”€ grounding/
â”‚   â”‚   â”œâ”€â”€ accessibility.py     # pywinauto UIA grounding
â”‚   â”‚   â”œâ”€â”€ visual.py            # VLM-based visual grounding
â”‚   â”‚   â””â”€â”€ ocr.py               # RapidOCR text detection
â”‚   â”œâ”€â”€ actions/
â”‚   â”‚   â”œâ”€â”€ keyboard.py          # Keyboard input executor
â”‚   â”‚   â”œâ”€â”€ mouse.py             # Mouse input executor
â”‚   â”‚   â”œâ”€â”€ shell.py             # Shell command executor
â”‚   â”‚   â”œâ”€â”€ window.py            # Window manager
â”‚   â”‚   â””â”€â”€ compositor.py        # Action dispatch & retry (16 types)
â”‚   â”œâ”€â”€ agent/
â”‚   â”‚   â”œâ”€â”€ base.py              # Base agent ABC & data classes
â”‚   â”‚   â”œâ”€â”€ navigator.py         # Core ReAct navigator agent
â”‚   â”‚   â”œâ”€â”€ planner.py           # LLM task decomposition
â”‚   â”‚   â”œâ”€â”€ state_validator.py   # Post-action state validation
â”‚   â”‚   â”œâ”€â”€ recovery.py          # Per-app recovery strategies
â”‚   â”‚   â”œâ”€â”€ step_memory.py       # Cached step patterns
â”‚   â”‚   â”œâ”€â”€ reinforcement.py     # Tabular Q-learning (RL)
â”‚   â”‚   â””â”€â”€ human_teacher.py     # Learning from Demonstration (LfD)
â”‚   â”œâ”€â”€ mcp/
â”‚   â”‚   â””â”€â”€ server.py            # FastMCP server (11 tools)
â”‚   â””â”€â”€ evaluation/
â”‚       â”œâ”€â”€ metrics.py           # Benchmark metrics & reporting
â”‚       â””â”€â”€ tasks.py             # 30 built-in benchmark tasks
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ run_demo_detached.py     # Live demo runner (4 demos)
â”‚   â”œâ”€â”€ human_teach.py           # Human teaching CLI
â”‚   â”œâ”€â”€ run_benchmark.py         # Benchmark runner
â”‚   â””â”€â”€ record_demo.py           # GIF demo recorder
â”œâ”€â”€ recordings/
â”‚   â”œâ”€â”€ demo1_settings.gif       # Demo 1 recording
â”‚   â”œâ”€â”€ demo2_edge_video.gif     # Demo 2 recording
â”‚   â”œâ”€â”€ demo4_file_explorer.gif  # Demo 4 recording
â”‚   â”œâ”€â”€ rl_qtable.json           # Persistent Q-table
â”‚   â”œâ”€â”€ step_memory.json         # Cached step patterns
â”‚   â””â”€â”€ teaching/                # Learned demonstration patterns
â”œâ”€â”€ paper/                       # Academic paper (LaTeX)
â”œâ”€â”€ tests/                       # Unit test suite
â”œâ”€â”€ pyproject.toml               # Project config & dependencies
â”œâ”€â”€ CLAUDE.md                    # Project memory for AI agents
â””â”€â”€ README.md                    # This file
```

## ğŸ¬ Live Demo Results

Real demos run on Windows 11 with GPT-4o (Azure OpenAI):

| Demo | Task | Steps | Time | Status | Iterations |
|------|------|-------|------|--------|------------|
| **Demo 1** | System Tray: Set brightness to 100% | 5 | 68s | âœ… SUCCESS | 1 |
| **Demo 2** | Edge: Play 4K YouTube video fullscreen | 9 | 138s | âœ… SUCCESS | 9 |
| **Demo 3** | Outlook email + Teams message | â€” | â€” | ğŸ”„ In Progress | 2 |
| **Demo 4** | File Explorer: Create folder in Downloads | 15 | 220s | ğŸ”„ In Progress | 3 |

### Key Innovations Discovered Through Iteration

- **UIA Slider Control** (Demo 1): Direct `RangeValuePattern.SetValue()` via UIA â€” 100% reliable vs. unreliable mouse drag
- **Content Verification** (Demo 2): Post-click window title check + RL negative reward for wrong content
- **Recovery-Aware Actions** (Demo 4): Auto-recovery (Escape) can sabotage in-progress operations like folder rename â€” solved with per-app recovery disabling
- **Done Verification** (Demo 4): Filesystem path check before accepting task completion â€” prevents false success

## ğŸ§  Learning Systems

### Reinforcement Learning
- **Algorithm**: Tabular Q-learning with TD update ($\alpha=0.15$, $\gamma=0.9$)
- **State**: Hash of UI context (window title + element count + top elements)
- **Rewards**: +2.0 (done success), +0.3 (state changed), -0.7 (drift), -1.2 (wrong content)
- **Persistence**: Q-table saved to `recordings/rl_qtable.json` across sessions

### Human Teaching (Learning from Demonstration)
- **11 teaching topics** defined (slider, navigation, folder creation, email, etc.)
- **1 pattern learned** so far: "Creating a new folder in File Explorer"
- **Workflow**: Record human demo â†’ extract trajectory pattern â†’ inject into LLM context
- **CLI**: `python scripts/human_teach.py --topic <topic_id>`

## ğŸ“Š Benchmark Results

AgenticOS includes a comprehensive benchmark suite with 30 tasks:

| Category       | Tasks | Description                                        |
|---------------|-------|----------------------------------------------------|
| **Basic**      | 15    | Single-app operations (Notepad, Calculator, Explorer) |
| **Intermediate** | 10 | Multi-step workflows, settings, clipboard            |
| **Advanced**   | 5     | Multi-app coordination, error recovery               |

### Comparison with Existing Systems

| System         | Architecture     | Grounding        | Success Rate | Open Source |
|---------------|------------------|------------------|-------------|-------------|
| **AgenticOS** | Modular ReAct    | UIA+Vision+OCR  | TBD         | âœ…           |
| UFOÂ²           | Dual-agent       | UIA + Vision     | 30.5%*      | âœ…           |
| Operator       | CUA              | Vision only      | 20.8%*      | âŒ           |
| Navi           | Foundation model | Vision only      | 19.5%*      | âŒ           |
| Claude CU      | ReAct            | Vision only      | â€”           | âŒ           |

*Results from OSWorld benchmark (Ubuntu). Windows results may differ.

## ğŸ”§ Configuration

AgenticOS uses environment variables or `.env` files:

| Variable              | Default                          | Description                  |
|-----------------------|----------------------------------|------------------------------|
| `ANTHROPIC_API_KEY`   | â€”                                | Anthropic API key            |
| `OPENAI_API_KEY`      | â€”                                | OpenAI API key               |
| `AGENTICOS_MODEL`     | `claude-sonnet-4-20250514`   | LLM model to use             |
| `AGENTICOS_MAX_STEPS` | `15`                             | Max steps per task           |
| `AGENTICOS_GROUNDING` | `hybrid`                         | Grounding mode               |
| `AGENTICOS_CONFIRM`   | `true`                           | Confirm before actions       |

## ğŸ§ª Development

```bash
# Run tests
pytest tests/ -v

# Run with coverage
pytest tests/ --cov=agenticos --cov-report=term-missing

# Lint
ruff check src/ tests/

# Type check
mypy src/agenticos/

# Format
ruff format src/ tests/
```

## ğŸ“„ Academic Paper

See [paper/](paper/) for the full LaTeX source of our paper:

> **AgenticOS: A Modular Framework for Deep OS Integration and Intelligent Desktop Automation**

The paper presents our architecture, compares against existing systems (UFOÂ², Operator, Claude Computer Use, OmniParser), and evaluates performance on our 30-task benchmark suite.

## ğŸ“œ License

[MIT License](LICENSE) â€” see LICENSE file for details.

## ğŸ™ Acknowledgments

- [UFO](https://github.com/microsoft/UFO) â€” Microsoft's UI-Focused Agent for Windows
- [OmniParser](https://github.com/microsoft/OmniParser) â€” Screen Parsing Toolkit
- [litellm](https://github.com/BerriAI/litellm) â€” Multi-LLM provider proxy
- [pywinauto](https://github.com/pywinauto/pywinauto) â€” Windows UI Automation
- [FastMCP](https://github.com/jlowin/fastmcp) â€” Model Context Protocol SDK
